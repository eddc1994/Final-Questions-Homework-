{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Choice Question\n",
    "\n",
    "Q1. What types can be used in Lists?<br>\n",
    "a) Strings<br>\n",
    "b) Ints<br>\n",
    "c) Bools<br>\n",
    "d) All the above<br>\n",
    "Answer: (d) All the above<br>\n",
    "<br>\n",
    "Q2. Given an imported library, matplotlib.pyplot as plt, what is NOT a function of plt?<br>\n",
    "a) plt.plot()<br>\n",
    "b) plt.python()<br>\n",
    "c) plt.scatter()<br>\n",
    "d) plt.hist()<br>\n",
    "Answer: (b) plt.python()<br>\n",
    "<br>\n",
    "Q3. What is NOT an effective Exploratory Data Analysis method?<br>\n",
    "a) Staring at data<br>\n",
    "b) Histograms<br>\n",
    "c) Bee Swarm Plot<br>\n",
    "d) Empirical cumulative distribution function (ECDF)<br>\n",
    "Answer: (a) Staring at data<br>\n",
    "<br>\n",
    "Q4. What is NOT a supervised learning algorithm?<br>\n",
    "a) KMeans<br>\n",
    "b) K-NN<br>\n",
    "c) Neural Network<br>\n",
    "d) Linear Regression<br>\n",
    "Answer: (a) KMeans<br>\n",
    "<br>\n",
    "Q5. A convolution neural network can be used for...<br>\n",
    "a) Linear combination<br>\n",
    "b) Digital filter<br>\n",
    "c) A way to create new features<br>\n",
    "d) All the above<br>\n",
    "Answer: (d) All the above<br>\n",
    "<br>\n",
    "Q6. Which of these cannot be used for dimension reduction?<br>\n",
    "a) Non-negative matrix factorization<br>\n",
    "b) Principal Component Analysis<br>\n",
    "c) Mean Squared Error<br>\n",
    "d) t-SNE<br>\n",
    "Answer: (c) Mean Squared Error<br>\n",
    "<br>\n",
    "Q7. The architecture of a neural net is similar to...<br>\n",
    "a) Object-Oriented Programming<br>\n",
    "b) The Human Brain<br>\n",
    "c) MIPs architecture<br>\n",
    "d) Airplane<br>\n",
    "Answer: (b) The Human Brain<br>\n",
    "<br>\n",
    "Q8. What can word tokenization NOT do?<br>\n",
    "a) Breaking out words or sentences<br>\n",
    "b) Seperating punctuation<br>\n",
    "c) Eating words<br>\n",
    "d) Seperate all hashtags in a tweet<br>\n",
    "AnswerL (c) Eating words<br>\n",
    "# True / False Questions\n",
    "\n",
    "Q9. Seaborn is a complement of Matplotlib<br>\n",
    "True or False<br>\n",
    "Answer: True<br>\n",
    "<br>\n",
    "Q10. A condidence interval measures the range of sample<br>\n",
    "True or False<br>\n",
    "Answer: False<br>\n",
    "<br>\n",
    "Q11. You should not do EDA first on data before anything else<br>\n",
    "True or False<br>\n",
    "Answer: False<br>\n",
    "<br>\n",
    "Q12. The gradient decent solution for least squares iteratively changes the slope to lower the error<br>\n",
    "True of False<br>\n",
    "Answer: True<br>\n",
    "<br>\n",
    "Q13. You need to use an even number of K for KNN to prevent a draw<br>\n",
    "True or False<br>\n",
    "Answer: False<br>\n",
    "<br>\n",
    "Q14. P-value is the probability that the null hypothesis is true.<br>\n",
    "True or False<br>\n",
    "Answer: False<br>\n",
    "<br>\n",
    "Q15. Workflow for optimizing model capacity is to start with a small network and gradually increase capacity<br>\n",
    "True or False<br>\n",
    "Answer: True<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short Answer Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Implement Bernoulli's Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given n and p, implement Bernoulli's Trial\n",
    "import numpy as np\n",
    "\n",
    "def bernoullis_trial(n, p):\n",
    "#n = # of iterations and p is the probability of success\n",
    "    #Inital # of success : num_success\n",
    "    num_success = ----\n",
    "    \n",
    "    #Perform Trial\n",
    "    for ---- in ----:\n",
    "        #Random number between 0 and 1: random_num\n",
    "        random_num = ----\n",
    "        \n",
    "        #Check if random number is less than p\n",
    "        if ---- < ----:\n",
    "            #increment success\n",
    "            -----\n",
    "    #return number of success\n",
    "    return ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def bernoullis_trial(n, p):\n",
    "#n = # of iterations and p is the probability of success\n",
    "    #Inital # of success : num_success\n",
    "    num_success = 0\n",
    "    \n",
    "    #Perform Trial\n",
    "    for i in range(n):\n",
    "        #Random number between 0 and 1: random_num\n",
    "        random_num = np.random.random()\n",
    "        \n",
    "        #Check if random number is less than p\n",
    "        if random_num < p:\n",
    "            #increment success\n",
    "            num_success += 1\n",
    "    #return number of success\n",
    "    return num_success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Given story, print and tokenize the second sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "scene_one = \"Machine Learning with NLTK. This is a sentence you're going to be printing out. Good bye now!\"\n",
    "\n",
    "# Split scene_one into sentences: sentences\n",
    "____ = ----\n",
    "\n",
    "# Use word_tokenize to tokenize the second sentence: tokenized_sent\n",
    "____ = ----\n",
    "\n",
    "# Print the tokenized sentence\n",
    "print(----)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "scene_one = \"Machine Learning with NLTK. This is a sentence you're going to be printing out. Have fun!\"\n",
    "\n",
    "# Split scene_one into sentences: sentences\n",
    "sentences = sent_tokenize(scene_one)\n",
    "\n",
    "# Use word_tokenize to tokenize the second sentence: tokenized_sent\n",
    "tokenized_sent = word_tokenize(sentences[1])\n",
    "\n",
    "# Print the tokenized sentence\n",
    "print(tokenized_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. Generate 100 random numbers and make a histogram of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Number of numbers generated : n\n",
    "n = ----\n",
    "\n",
    "# Generate 100 random numbers between 1 and 100 : random_numbers\n",
    "random_numbers = ----\n",
    "\n",
    "# Compute number of bins by taking a square root of numbers generated : n_bins\n",
    "n_bins = ----\n",
    "\n",
    "# Plot the histogram\n",
    "----(----, bins = ----, edgecolor = 'black')\n",
    "\n",
    "# Label the axis x then y\n",
    "----(\"Random Numbers\")\n",
    "----(\"Occurances\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Number of numbers generated : n\n",
    "n = 100\n",
    "\n",
    "# Generate 100 random numbers between 1 and 100 : random_numbers\n",
    "random_numbers = [random.randint(1,100) for i in range(n)]\n",
    "\n",
    "# Compute number of bins by taking a square root of numbers generated : n_bins\n",
    "n_bins = int(np.sqrt(n))\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(random_numbers, bins = n_bins, edgecolor = 'black')\n",
    "\n",
    "# Label the axis\n",
    "plt.xlabel(\"Random Numbers\")\n",
    "plt.ylabel(\"Occurances\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Given with iris data set, use fill in for KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Loading dataset for you\n",
    "data = load_iris()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data['target']\n",
    "\n",
    "# Create feature and target arrays\n",
    "X = ----\n",
    "y = ----\n",
    "\n",
    "# Split into training and test set with test_size as 20%, and random state at 42\n",
    "X_train, X_test, y_train, y_test = ----(----, ----, test_size = ----, random_state= ----, stratify=y)\n",
    "\n",
    "# Create a k-NN classifier with 5 neighbors: knn\n",
    "knn = ----\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(----,----)\n",
    "\n",
    "# Print the accuracy\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Loading dataset for you\n",
    "data = load_iris()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data['target']\n",
    "\n",
    "# Create feature and target arrays\n",
    "X = df.drop(['target'], axis = 1)\n",
    "y = df['target']\n",
    "\n",
    "# Split into training and test set with test_size as 20%, and random state at 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state=42, stratify=y)\n",
    "\n",
    "# Create a k-NN classifier with 5 neighbors: knn\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Generate 100 random numbers between 1 and 100 and return numbers that are bigger than 50. Must use list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def num_bigger_than_50(n):\n",
    "    # Generate 100 random numbers between 1 and 100 : random_numbers\n",
    "    random_numbers = ----\n",
    "    \n",
    "    #return numbers bigger than 50\n",
    "    return ----\n",
    "\n",
    "#print out result with n = 100\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def num_bigger_than_50(n):\n",
    "    # Generate 100 random numbers between 1 and 100 : random_numbers\n",
    "    random_numbers = [random.randint(1,100) for i in range(n)]\n",
    "    \n",
    "    #return numbers bigger than 50\n",
    "    return [i for i in random_numbers if i > 50]\n",
    "\n",
    "#print out result with n = 100\n",
    "num_bigger_than_50(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Set Mini Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. From sklearn.datasets load digits. <br> \n",
    "Apply train_test_split to data with test size of 20% and random state of 42.<br>\n",
    "Use KNN with n = 7 and print out accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "# Create feature and target arrays\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state=42)\n",
    "\n",
    "# Create a k-NN classifier with 7 neighbors: knn\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
